# ğŸ”¥ CloudOps Automation at Scale ğŸ¦…

ğŸŒŸ You can use [CloudOps Automation Runbooks](https://cloudops.oceansoft.io), built on Jupyter Notebooks, to quickly create SRE RunBooks for Runbook Automation and Cloud Infrastructure Management! ğŸŒ

> [!IMPORTANT]
> **ğŸ† Mission**: Our mission is to simplify CloudOps Automation for DevOps and SRE teams by providing an extensive, community-driven repository of actions and runbooks that streamline day-to-day operations. 

> [!NOTE]
> **ğŸ‘ï¸ Vision**: Our vision is to be the ğŸ¥‡ One-Stop Multi-Cloud Platform Engineering & Best Practices Solution for all CloudOps Automation needs, allowing DevOps and SRE teams to automate their workflows with ease, improve efficiency, and minimize toil.

[![ğŸ CloudOps PyPI version](https://img.shields.io/pypi/v/cloudops)](https://pypi.org/project/cloudops/)

<div align="left">
  <a href="https://www.linkedin.com/in/nnthanh" target="blank"><img align="center" src="https://img.shields.io/badge/-nnthanh-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/nnthanh/" alt="Nhat-Thanh Nguyen" height="25" width="100" /></a>
  <a href="https://github.com/nnthanh101/" target="blank"><img align="center" src="https://img.shields.io/github/followers/nnthanh101?label=Follow&style=social&link=https://github.com/nnthanh101/" alt="Thanh Nguyen" height="25" width="100" /></a>
  <a href="https://www.facebook.com/groups/platformengineering" target="blank"><img align="center" src="https://img.shields.io/badge/Facebook-blue?style=flat-square&logo=facebook&logoColor=white&link=[https://www.linkedin.com/in/nnthanh/](https://www.facebook.com/groups/platformengineering)" alt="Nhat-Thanh Nguyen" height="25" width="100" /></a>  
</div>

---

## Features

- [x] ğŸ› ï¸ configuration in a single file [`pyproject.toml`](pyproject.toml)
- [x] ğŸ“¦ [`uv`](https://docs.astral.sh/uv/) as package manager: **Fast Dependency Management** â€“ UV optimizes builds and installations.  
- [x] ğŸ’… [`ruff`](https://docs.astral.sh/ruff/) for simplifies linting and formatting
- [x] ğŸ§ª [`pytest`](https://docs.pytest.org/en/stable/), supports AWS SDK mocking and validation.   
- [x] ğŸ§¹ [`Taskfile`](Taskfile) with code quality checks
- [ ] ğŸ“š auto doc generation
- [ ] **CLI Tools** â€“ Typer simplifies automation for AWS resources.  
- [ ] **Logging** â€“ Loguru ensures structured logs for debugging. 
- [x] ğŸ³ CI/CD Optimized Docker Image runs when a new *release* is created pushing to gh registry
- [x] ğŸ¦¾ GitHub actions:
    - [x] auto publish to [`pypi`](https://pypi.org/) on push on `main`
    - [ ] auto creating a new tag on push on `main`, sync versions
    - [x] run `tests` and `lint` on `dev` and `main` when a PR is open

## Project Structure

> ğŸ›  End-to-end Production-grade project structure for successful ğŸ’ CloudOps Automation and Visual Analytics FinOps projects ğŸš€

```
cloudops-automation/
â”œâ”€â”€ .devcontainer/     ## Dev Container configurations
â”‚   â””â”€â”€ Dockerfile     ## Container image build file
â”œâ”€â”€ .github/           ## CI/CD workflows
â”‚   â”œâ”€â”€ workflows/     ## GitHub Actions workflows
â”‚   â””â”€â”€ templates/     ## Workflow templates
â”œâ”€â”€ .vscode/           ## IDE-specific configurations
â”œâ”€â”€ config/            ## Configuration files (YAML, JSON)
â”œâ”€â”€ data               ğŸ” Where all your raw and processed data files are stored.
â”‚   â”œâ”€â”€ external       <- Data from third-party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, unprocessed, immutable data dump.
â”‚
â”œâ”€â”€ docs               ğŸ““ A default mkdocs project; see mkdocs.org for details
â”‚   â”œâ”€â”€ api/                 ## API documentation
â”‚   â”œâ”€â”€ architecture/        ## Architecture diagrams
â”‚   â”œâ”€â”€ tutorials/           ## Tutorials and guides
â”‚   â”œâ”€â”€ getting-started.md   ## Quickstart guide
â”‚   â””â”€â”€ index.md             ## Overview documentation
â”‚
â”œâ”€â”€ logs/                    ## Log files for debugging
|
â”œâ”€â”€ models             ğŸ§  Store your trained and serialized models for easy access and versioning.
â”‚
â”œâ”€â”€ notebooks          ğŸ’» Jupyter notebooks for experiments and visualization.
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â”œâ”€â”€ data_preprocessing.ipynb
â”‚   â”œâ”€â”€ model_training.ipynb
â”‚   â””â”€â”€ model_evaluation.ipynb
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for 
â”‚                         cloudops and configuration for tools like black
â”‚
â”œâ”€â”€ src/                            ## ğŸ§© Source code for use in this project.
â”‚   â”œâ”€â”€ cloudops/                   ## Main module for CloudOps automation
â”‚   â”‚   â”œâ”€â”€ __init__.py             ## Package initializer
â”‚   â”‚   â”œâ”€â”€ s3.py                   ## S3 utility functions
â”‚   â”‚   â”œâ”€â”€ ec2.py                  ## EC2 automation
â”‚   â”‚   â”œâ”€â”€ rds.py                  ## RDS management
â”‚   â”‚   â”œâ”€â”€ runbooks/               ## Automation runbooks
â”‚   â”‚   â”‚   â”œâ”€â”€ backup.py           ## Automated backup runbook
â”‚   â”‚   â”‚   â”œâ”€â”€ scale-out.py        ## Scale-out automation runbook
â”‚   â”‚   â”‚   â””â”€â”€ cleanup.py          ## Cleanup automation runbook
â”‚   â”œâ”€â”€ utils/                      ## Utility scripts (logging, configs)
â”‚   â”œâ”€â”€ cli/                        ## Command-line interface
â”‚   â”‚   â”œâ”€â”€ __init__.py             ## CLI module initializer
â”‚   â”‚   â”œâ”€â”€ main.py                 ## CLI entry point
â”‚   â”‚   â””â”€â”€ commands.py             ## CLI commands
â”‚   â””â”€â”€ tests/                      ## Unit and integration tests
â”‚       â”œâ”€â”€ test_s3.py              ## Test cases for S3 module
â”‚       â”œâ”€â”€ test_ec2.py             ## Test cases for EC2 module
â”‚       â””â”€â”€ test_runbooks.py        ## Test cases for runbooks
â”œâ”€â”€ templates/                      ## Terraform and CloudFormation templates
â”œâ”€â”€ tools/                          ## Developer tools and scripts
â”œâ”€â”€ .dockerignore                   ## Docker ignore file
â”œâ”€â”€ .env                            ## Environment variables
â”œâ”€â”€ .gitignore                      ## Git ignore file
â”œâ”€â”€ .python-version                 ## Python version management
â”œâ”€â”€ .gitignore
â”œâ”€â”€ mkdocs.yml                      # Documentation generator configuration
â”œâ”€â”€ README.md          ğŸ¤ Explain your project and its structure for better collaboration.
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            ğŸ“Š Generated analysis (reports, charts, and plots) as HTML, PDF, LaTeX.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   ğŸ›  The requirements file for reproducing the analysis environment, for easy environment setup.
â””â”€â”€ Taskfile           <- Taskfile with convenience commands like `task data` or `task train`

```

## Getting started

### Installation

To set it up and run

```bash
uv venv
uv sync
```
Then

```bash
python main.py
```

Will output a random joke

```
Why did the cow in the pasture get promoted at work? ...  Because he is OUT-STANDING in his field!
```

### Development

You can install in `editable` mode the library

```bash
uv pip install -e .
```

You can now run, for example, a function defined as `scripts` in the [`pyproject.toml`](pyproject.toml)

```bash
make_me_laugh
```

### Linting

```
ruff check
```


### Formatting

```
ruff format
```

## CI/CD

### Tests
Tests inside `/tests` are run using [`pytest`](https://docs.pytest.org/en/stable/) on PR both on `dev` and `main`

### Publish Package
 In order to publish to [pypi](https://pypi.org/) you need to create a secret called `UV_PUBLISH_TOKEN` with your [pypi access token](https://pypi.org/manage/account/) under **API tokens**.


### Docker
[`Dockerfile`](Dockerfile) contains a multi stage build that uses `--compile-bytecode` to compite your package. For this example, the resulting image is just

```bash
docker build -t python-template .
```

```
REPOSITORY        TAG       IMAGE ID       CREATED          SIZE
python-template   latest    1ded7d260b1c   58 seconds ago   55.4MB
```

The image is build using the [`build`](.github/workflows/build.yml) workflow when a new *relaese* is created

---
